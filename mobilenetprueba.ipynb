{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-27 12:14:14.612917: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import random\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import json \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "photos = pd.read_json(\"photos.json\", lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "photos1 = photos.drop(columns=['caption'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "photos2 = photos1.drop(columns=['business_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_1(photo_id): #aplicamos un filtro para las imágenes corruptas del df\n",
    "    try:\n",
    "        Image.open(f\"photos2/{photo_id}.jpg\")\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "lista_images = photos2[\"photo_id\"].to_list()\n",
    "corrupt_images = []\n",
    "for imagen in lista_images:\n",
    "     if not df_1(imagen):\n",
    "         corrupt_images.append(imagen)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IGUALAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def igualar1(photos2, etiqueta_columna, valor_columna, etiqueta_valor, num_filas):\n",
    "    # Filtrar las filas que tienen la etiqueta específica\n",
    "    filas_etiqueta = photos2[photos2[etiqueta_columna] == etiqueta_valor]\n",
    "    \n",
    "    # Verifica que num_filas no sea mayor que el total de filas con la etiqueta específica\n",
    "    if num_filas > len(filas_etiqueta):\n",
    "        raise ValueError(\"Error, coge un número más chico\")\n",
    "    \n",
    "    # Seleccionar aleatoriamente los índices de las filas a eliminar\n",
    "    indices_a_eliminar = np.random.choice(filas_etiqueta.index, num_filas, replace=False)\n",
    "    \n",
    "    # Eliminar las filas seleccionadas del dataset original\n",
    "    photos3 = photos2.drop(indices_a_eliminar)\n",
    "    \n",
    "    return photos3 #photos3 se aplicará al df con la reducción de la etiqueta \"food\"\n",
    "\n",
    "# Parámetros\n",
    "etiqueta_columna = 'label'  # Nombre de la columna con la etiqueta\n",
    "valor_columna = 'photo_id'       # Nombre de la columna con el valor asociado\n",
    "etiqueta_valor = 'food'            # Valor específico de la etiqueta\n",
    "num_filas = 106000                   # Número de filas a eliminar\n",
    "\n",
    "# Eliminar filas con la etiqueta específica y su valor asociado\n",
    "photos3 = igualar1(photos2, etiqueta_columna, valor_columna, etiqueta_valor, num_filas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def igualar2(photos3, etiqueta_columna, valor_columna, etiqueta_valor, num_filas):\n",
    "    \n",
    "    filas_etiqueta = photos3[photos3[etiqueta_columna] == etiqueta_valor]\n",
    "    \n",
    "    \n",
    "    if num_filas > len(filas_etiqueta):\n",
    "        raise ValueError(\"Error, coge un número más chico\")\n",
    "    \n",
    "    \n",
    "    indices_a_eliminar = np.random.choice(filas_etiqueta.index, num_filas, replace=False)\n",
    "    \n",
    "    \n",
    "    photos4 = photos3.drop(indices_a_eliminar)\n",
    "    \n",
    "    return photos4 #photos4 se aplicará al df con la reducción de la etiqueta \"inside\"\n",
    "\n",
    "# Parámetros\n",
    "etiqueta_columna = 'label'  # Nombre de la columna con la etiqueta\n",
    "valor_columna = 'photo_id'       # Nombre de la columna con el valor asociado\n",
    "etiqueta_valor = 'inside'            # Valor específico de la etiqueta\n",
    "num_filas = 53802                  # Número de filas a eliminar\n",
    "\n",
    "\n",
    "photos4 = igualar2(photos3, etiqueta_columna, valor_columna, etiqueta_valor, num_filas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def igualar3(photos4, etiqueta_columna, valor_columna, etiqueta_valor, num_filas):\n",
    "    \n",
    "    filas_etiqueta = photos4[photos4[etiqueta_columna] == etiqueta_valor]\n",
    "    \n",
    "    \n",
    "    if num_filas > len(filas_etiqueta):\n",
    "        raise ValueError(\"Error, coge un número más chico\")\n",
    "    \n",
    "    \n",
    "    indices_a_eliminar = np.random.choice(filas_etiqueta.index, num_filas, replace=False)\n",
    "    \n",
    "    \n",
    "    photos5 = photos4.drop(indices_a_eliminar)\n",
    "    \n",
    "    return photos5 #photos5 se aplicará al df con la reducción de la etiqueta \"outside\"\n",
    "\n",
    "# Parámetros\n",
    "etiqueta_columna = 'label'  # Nombre de la columna con la etiqueta\n",
    "valor_columna = 'photo_id'       # Nombre de la columna con el valor asociado\n",
    "etiqueta_valor = 'outside'            # Valor específico de la etiqueta\n",
    "num_filas = 16101                  # Número de filas a eliminar\n",
    "\n",
    "\n",
    "photos5 = igualar3(photos4, etiqueta_columna, valor_columna, etiqueta_valor, num_filas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def igualar4(photos5, etiqueta_columna, valor_columna, etiqueta_valor, num_filas):\n",
    "    \n",
    "    filas_etiqueta = photos5[photos5[etiqueta_columna] == etiqueta_valor]\n",
    "    \n",
    "    \n",
    "    if num_filas > len(filas_etiqueta):\n",
    "        raise ValueError(\"Error, coge un número más chico\")\n",
    "    \n",
    "    \n",
    "    indices_a_eliminar = np.random.choice(filas_etiqueta.index, num_filas, replace=False)\n",
    "    \n",
    "    \n",
    "    photos6 = photos5.drop(indices_a_eliminar)\n",
    "    \n",
    "    return photos6 #photos6 se aplicará al df con la reducción de la etiqueta \"drink\"\n",
    "\n",
    "# Parámetros\n",
    "etiqueta_columna = 'label'  # Nombre de la columna con la etiqueta\n",
    "valor_columna = 'photo_id'       # Nombre de la columna con el valor asociado\n",
    "etiqueta_valor = 'drink'            # Valor específico de la etiqueta\n",
    "num_filas = 13020                 # Número de filas a eliminar\n",
    "\n",
    "\n",
    "photos6 = igualar4(photos5, etiqueta_columna, valor_columna, etiqueta_valor, num_filas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIMPIO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_photos = photos6.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>photo_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6LJa8QZOGBjt9maE5miLhw</td>\n",
       "      <td>menu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>DtsfhqhqUB-tjs5XbwJfXw</td>\n",
       "      <td>menu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>9Wkj-Vl5EYLS6OIy4EYigw</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>RXtykJb7KIXHySXJJnlFfg</td>\n",
       "      <td>inside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>pRnGI7xv7ZBJ8p_w0xy9fg</td>\n",
       "      <td>drink</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  photo_id   label\n",
       "16  6LJa8QZOGBjt9maE5miLhw    menu\n",
       "69  DtsfhqhqUB-tjs5XbwJfXw    menu\n",
       "72  9Wkj-Vl5EYLS6OIy4EYigw    food\n",
       "82  RXtykJb7KIXHySXJJnlFfg  inside\n",
       "94  pRnGI7xv7ZBJ8p_w0xy9fg   drink"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_photos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Some image paths do not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m df_photos[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_path\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_photos[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mphoto_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(image_folder, x))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Verificar si las rutas de las imágenes existen\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m df_photos[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_path\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists)\u001b[38;5;241m.\u001b[39mall(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSome image paths do not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Codificar las etiquetas\u001b[39;00m\n\u001b[1;32m     11\u001b[0m le \u001b[38;5;241m=\u001b[39m LabelEncoder()\n",
      "\u001b[0;31mAssertionError\u001b[0m: Some image paths do not exist"
     ]
    }
   ],
   "source": [
    "# Ruta a la carpeta de imágenes\n",
    "image_folder = '/Users/florentinoromerourquiza/Documents/yelp_photos-002/photos'  # Asegúrate de ajustar la ruta\n",
    "\n",
    "# Añadir una columna con las rutas completas de las imágenes\n",
    "df_photos['image_path'] = df_photos['photo_id'].apply(lambda x: os.path.join(image_folder, x))\n",
    "\n",
    "# Verificar si las rutas de las imágenes existen\n",
    "assert df_photos['image_path'].apply(os.path.exists).all(), \"Some image paths do not exist\"\n",
    "\n",
    "# Codificar las etiquetas\n",
    "le = LabelEncoder()\n",
    "df_photos['label_encoded'] = le.fit_transform(df_photos['label'])\n",
    "\n",
    "# Convertir las etiquetas codificadas a cadenas\n",
    "df_photos['label_encoded'] = df_photos['label_encoded'].astype(str)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y validación\n",
    "train_df, val_df = train_test_split(df_photos, test_size=0.2, stratify=df_photos['label_encoded'], random_state=42)\n",
    "\n",
    "# Verificar si los DataFrames no están vacíos\n",
    "assert not train_df.empty, \"Training DataFrame is empty\"\n",
    "assert not val_df.empty, \"Validation DataFrame is empty\"\n",
    "\n",
    "# Parámetros\n",
    "img_height, img_width = 224, 224\n",
    "batch_size = 32\n",
    "num_classes = len(df_photos['label'].unique())\n",
    "\n",
    "# Generadores de datos con aumento de imagen\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    x_col='image_path',\n",
    "    y_col='label_encoded',\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    val_df,\n",
    "    x_col='image_path',\n",
    "    y_col='label_encoded',\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Cargar MobileNetV2 sin las capas superiores (headless)\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "\n",
    "# Congelar las capas base\n",
    "base_model.trainable = False\n",
    "\n",
    "# Añadir nuestras propias capas\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Crear el modelo completo\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator\n",
    ")\n",
    "\n",
    "# Evaluación y cálculo del F1-score\n",
    "val_generator.reset()\n",
    "preds = model.predict(val_generator, steps=val_generator.n // batch_size + 1)\n",
    "pred_labels = np.argmax(preds, axis=1)\n",
    "true_labels = val_df['label_encoded'].astype(int).values\n",
    "\n",
    "# Calcular F1-score\n",
    "f1 = f1_score(true_labels, pred_labels, average='weighted')\n",
    "print(f\"F1-score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
